# Task: Sequence video verification
## Dataset: CSV
**Prompt**  

I want you to act as a professional annotator. You need to generate the question-and-answer pair data to train the model based on the provided data. I will give you the image sampled from the video or the image caption or video summary of this video and the original labels. All the information that the answer needs is contained in the label files. Please remember you are a professional annotator and finish your work as required. Do not consider to brefily the generation.

There are some rules you need to obey:  

<!-- 1）For generating questions：    
Based on the provided image,  provide more detail for the original question:  
- Define the question type from the requirements, such as judgment questions or essay questions. 
- Create a background story and a person's motivation to provide context and understanding of the scene. For example, give an introduction, then tell me why I want to ask you the question. If I get the answer, write what I will achieve.   
- Describe the activity taking place without directly mentioning the action being performed.   
- You should do as well as possible to generate all kinds of stories.   
- please ensure the question and answer have all kinds of formats and stories.  
- Generate more and more kinds of background stories. Do not use one.   -->

1) For generating questions based on the provided image:

- **Question Type**: Start by defining the question type from the requirements. It could be a judgment question, essay question, or any other specified format.
  
- **Contextual Background**: Craft a background story that provides a context to the scene depicted in the image. This might involve describing the setting, the time, the atmosphere, or any relevant details that set the stage.

- **Motivation**: Explain the motivation or reason behind the question. For instance, begin with an introduction explaining the scenario or situation, then delve into why this particular question is being asked. Further, indicate what one hopes to achieve or understand by getting the answer.

- **Activity Description**: Describe the activities or events taking place in the image, but avoid direct mentions of the exact action being performed.

- **Variety in Storytelling**: Ensure a diverse range of background stories. Repeating the same story or context should be avoided.

- **Diversity in Format**: The generated questions and answers should come in a variety of formats and narratives to cater to different interpretations of the image.


2） For generating answer:
Based on the annotation and original answer:
- First of all, you need to generate the standard original answer based on the annotations of this video for the original question.
- Following the generated question by you, you need to write many details. Examine the provided image carefully based on the supplied photograph or image caption. Describe the scene in great detail, focusing on the primary action. 
- Additionally, elaborate on the potential context or background story that could explain the circumstances leading up to this moment.
     
3） the generated results:
- Ensure Variety: While maintaining continuity, make sure each pair is unique and captures different aspects of the source materials.
- Maintain Clarity: Despite the number of pairs, each question and answer should be clear, concise, and relevant to the source materials.
<!-- - you need to continuously generate 20 question-and-answer pairs one by one. Do not shorten the middle part of the generated result. You do not ask me that if the generated result's format and level of detail is acceptable, continue with the remaining pairs until finish all 20 pairs with the same data. When you finish it, I will give you new data. -->

4） the output format:

First of all， please use JSON format to reply to me.

Please follow this format to give the final result. Generate 10 continuous question-answer pairs based on the video annotations, images, and associated captions or video summaries. Do not include any interjected notes, disclaimers, or extraneous information. Simply produce the pairs consecutively. Do not pause, add notes, disclaimers, or any other commentary. Just provide 10 uninterrupted Q&A pairs.

```json
{
    "1":{
        "Original question": "This is the question provided by me or generated by you",
        "Original answer": "This is the answer you created based on the annotation and the original question",
        "The question with details": "Your generated question, elaborated in depth, which should adhere to the requirements and incorporate more narrative or motivation elements",
        "The answer with details": "Your answer, expanded and detailed, elaborated in depth, which should offer a comprehensive understanding by explaining the context, reasons, scene knowledge, action motivations, or other pertinent information.",
    },
    "2":{},
    ...
    "10":{},
}

```

If you understand my requirements, please tell me, and then I will send you a set of data which are the first question, an image or only image caption, the original question, and the original simple answer. When you finish the annotation generation, I will give your new data with new question to do this task again.

There is a example of the data original quesion and answer to help you to understand your chatacter and job:

- Input(provided by me):
    - Question 1: 
        - Objective(optional): In order to generate high-quality data pairs, I will add some new rules to help you.
        - Original question and answer:
            - Original question: what actions happened in the sequence video?
            - Original simple answer: As shown in JSON, it is the annotations of this video, that describe the action occure sequence.
                ```json
                "1.2":[
                    "take up the test tube",
                    "take up the iron clamp",
                    "screw the iron clamp",
                    "screw the iron clamp",
                    "take up the conical flask",
                    "pour the conical flask",
                    "put down the conical flask"
                ],
                ```
- Output(generated by you):
    ```json
    {
        "1":{
            "Original question": "This is the question provided by me or generated by you",
            "Original answer": "This is the answer you created based on the annotation and the original question",
            "The question with details": "Your generated question, elaborated in depth, which should adhere to the requirements and incorporate more narrative or motivation elements",
            "The answer with details": "Your answer, expanded and detailed, elaborated in depth, which should offer a comprehensive understanding by explaining the context, reasons, scene knowledge, action motivations, or other pertinent information.",
        },
        "2":{},
        ...
        "10":{},
    }
    ```
---  

- Question 1: 
  - Original quesion: what actions was happened in the sequence video?
  - Original simple answer: As shown in JSON, it is the annotations of this video, that describe the action occure sequence.
    ```json
    "1.2":[
        "take up the test paper",
        "tear the test paper",
        "put down the test paper",
        "put down the test paper",
        "take up the glass rod",
        "point the glass rod to evaporating dish",
        "point the glass rod to test paper",
        "put down the glass rod",
        "take up the tweezer",
        "clamp the tweezer",
        "put down the test paper",
        "put down the tweezer"
    ],
    ```


<!-- 
 Design judgment questions. Design the original question and answer first based on the annotation. Please pay attention to the action list, some actions are repetitive more than once. If you use such action in the answer or question, please add more information to help the model understand. Please ensure the response is No or Yes with the same probability. -->

- Question 2 : 
  - Objective: Create questions and answers based on you've provided the action sequences annatations, images, image's captions, or video summaries extracted from the original video. Questions should accurately reflect the depicted actions or described events. Answers should be limited to "Yes" or "No".
  
    - Subject Selection: 
        - The subject of the question can be any reasonable role that fits the context of the video. Examples include but are not limited to: "instructor", "lab assistant", "student", "chemist", "researcher".
        - Feel free to change or vary the subject across different question-and-answer pairs.
    - Action Selection: 
        - Choose two or more actions from the provided action sequence list. When choosing repetitive actions, make sure to provide clarity by adding slight variations or contexts.
    - Temporal Relationship: 
        - Integrate temporal relationships among the chosen actions in the question, such as "before", "after", "while", "until", "and then", etc.
        - Ensure clarity in the sequence, especially when the number of actions exceeds two
    - Flexibility: Frame the question in any manner that best captures the essence of the chosen actions and their sequence. Examples:
        - "After doing [action A], did the [chosen subject] proceed to [action B]?"
        - "In the video, was [action A] followed by [action B] and then [action C] by the [chosen subject]?"
        - "Did the sequence involve the [chosen subject] first doing [action A], and later [action B]?"
    - Answer: The answer should be either "Yes" or "No". Please ensure the response is No or Yes with the same probability.
  - Original question and answer:
    - Original question: your designed judgment question.
    - Original simple answer: As shown in JSON, it is the annotations of this video, that describe the action occure sequence.
        ```json
        "1.2":[
            "take up the test tube",
            "take up the iron clamp",
            "screw the iron clamp",
            "screw the iron clamp",
            "take up the conical flask",
            "pour the conical flask",
            "put down the conical flask"
        ],
        ```
- Question 3: 
  - Original quesion: what actions was happened in the sequence video?
  - Original simple answer: As shown in json, it is the annotations of this video, which describes  the action occure sequnce.
    ```json
    "1.2":[
        "take up the test tube",
        "take up the iron clamp",
        "screw the iron clamp",
        "screw the iron clamp",
        "take up the conical flask",
        "pour the conical flask",
        "put down the conical flask"
    ],
    ```
```

```
